{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotion recognizer.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import soundfile\n",
        "import numpy as np \n",
        "import librosa  \n",
        "import glob \n",
        "import os # to use operating system dependent functionality\n",
        "from sklearn.model_selection import train_test_split # for splitting training and testing \n",
        "from sklearn.neural_network import MLPClassifier # multi-layer perceptron model \n",
        "from sklearn.metrics import accuracy_score # to measure how good we are\n",
        "def get_feature(file_name,mfccs,mel,chroma,contrast):\n",
        "    \n",
        "        data, sample_rate = librosa.load(file_name)\n",
        "        stft = np.abs(librosa.stft(data))\n",
        "        mfccs = np.mean(librosa.feature.mfcc(y=data, sr=sample_rate, n_mfcc=40).T, axis=0)\n",
        "        mel = np.mean(librosa.feature.melspectrogram(data, sr=sample_rate).T,axis=0)\n",
        "        chroma = np.mean(librosa.feature.chroma_stft(S=stft, sr=sample_rate).T,axis=0)\n",
        "        contrast = np.mean(librosa.feature.spectral_contrast(S=stft, sr=sample_rate).T,axis=0)\n",
        "        \n",
        "        \n",
        "    \n",
        "        return mfccs,mel,chroma,contrast\n",
        "\n",
        "# emotions in dataset\n",
        "list_emotion = {\n",
        "    \"01\": \"neutral\",\n",
        "    \"02\": \"calm\",\n",
        "    \"03\": \"happy\",\n",
        "    \"04\": \"sad\",\n",
        "    \"05\": \"angry\",\n",
        "    \"06\": \"fearful\",\n",
        "    \"07\": \"disgust\",\n",
        "    \"08\": \"surprised\"\n",
        "}\n",
        "\n",
        "# I am using only 3 emotions to observe,feel free to add more.\n",
        "classify_emotions = {\n",
        "    \"sad\",\n",
        "    \"happy\",\n",
        "    \"surprised\"\n",
        "    \n",
        "    \n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def load_data(test_size=0.2):\n",
        "    feature, y = [], []\n",
        "    for file in glob.glob(\"C:\\\\Users\\\\Documents\\\\ravdess data\\\\Actor_*\\\\*.wav\"):\n",
        "        basename = os.path.basename(file)  # get the base name of the audio file\n",
        "       \n",
        "        emotion = list_emotion[basename.split(\"-\")[2]]   # get the emotion label\n",
        "       \n",
        "        if emotion not in classify_emotions:    # we allow only classify_emotions we set\n",
        "            try:\n",
        "                mfccs,mel,chroma,contrast = get_feature(file)\n",
        "            except Exception as e:\n",
        "                print (\"Error encountered while parsing file: \", file)\n",
        "                continue\n",
        "            ext_features = np.hstack([mfccs,mel,chroma,contrast])\n",
        "            feature.append(ext_features)\n",
        "            y.append(emotion)\n",
        "        \n",
        "    # split the data to training and testing and return it\n",
        "    return train_test_split(np.array(feature), y, test_size=test_size, random_state=9)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "feature_train, feature_test, y_train, y_test = load_data(test_size=0.25)\n",
        "\n",
        "# using get_features() function\n",
        "print(\"Number of samples in training data:\", feature_train.shape[0])\n",
        "\n",
        "print(\"Number of samples in testing data:\", feature_test.shape[0])\n",
        "\n",
        "# predict 25% of data \n",
        "y_pred = clf.predict(feature_test)\n",
        "\n",
        "# calculate the accuracy\n",
        "accuracy = accuracy_score(y_true=y_test, y_pred=y_pred)\n",
        "\n",
        "print(\"Accuracy is: {:.2f}%\".format(accuracy*100))\n",
        "\n",
        "\n",
        "print(\"Number of features:\", feature_train.shape[1])"
      ],
      "metadata": {
        "id": "R8kaeoMlTVHc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}